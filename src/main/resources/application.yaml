server:
  port: 5014
  servlet:
    context-path: /profile-api
spring:
  application:
    name: hangout-profile-api
  servlet:
    multipart:
      max-file-size: 1GB
      max-request-size: 1048MB
  datasource:
    driver-class-name: org.postgresql.Driver
    url: jdbc:postgresql://${DB_URL}/${DB_NAME}
    username: ${DB_USERNAME}
    password: ${DB_PASSWORD}
  jpa:
    properties:
      hibernate:
        "[format_sql]": false
    hibernate:
      ddl-auto: update
    show-sql: false
  output:
    ansi:
      enabled: ALWAYS
  kafka:
    bootstrap-servers: ${KAFKA_SERVER}
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer

logging:
  level:
    root: info
    # traceID and spanId are predefined MDC keys - we want the logs to include them
  pattern:
    level: "%5p [${spring.application.name:},%X{trace_id},%X{span_id}]"

management:
  # All traces should be sent to latency analysis tool
  tracing:
    sampling:
      probability: 1.0
  otlp:
    tracing:
      compression: gzip
  endpoints:
    web:
      exposure:
        include: prometheus, health
  # For Exemplars to work we need histogram buckets
  metrics:
    distribution:
      percentiles-histogram:
        http:
          server:
            requests: true

otel:
  exporter:
    otlp:
      endpoint: ${OTEL_COLLECTOR}
  instrumentation:
    micrometer:
      enabled: true

minio:
  url: ${MINIO_SERVER}
  accessKey: ${MINIO_ACCESS_KEY}
  secretKey: ${MINIO_SECRET_KEY}

hangout:
  kafka:
    content:
      topic: ${CONTENT_TOPIC}
  allowed-origins:
    url: ${CLIENT_ORIGINS}
  media:
    upload-bucket: ${UPLOAD_BUCKET}
  auth-service:
    url: ${AUTH_SERVICE}
